{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b74378-c237-4870-b63b-0a4af9b1fc59",
   "metadata": {
    "id": "e0b74378-c237-4870-b63b-0a4af9b1fc59"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23128353-099e-431b-adcb-dac428d3f645",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23128353-099e-431b-adcb-dac428d3f645",
    "outputId": "1b1a22f1-215c-46f4-ee98-93a5e682f8fb"
   },
   "outputs": [],
   "source": [
    "# Example is based on instructions from\n",
    "# https://github.com/kach/gradient-descent-the-ultimate-optimizer,\n",
    "# which contains the original source code for the Gradient Descent: The Ultimate Optimizer paper,\n",
    "# and the modified source code for experimental results with the CIFAR-10 dataset.\n",
    "\n",
    "class CIFAR10_CNN(nn.Module):\n",
    "    def __init__(self, inp_dim, num_hid, num_out):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1_filters = 16\n",
    "        self.conv1_kernel_size = (3,3)\n",
    "        self.conv1 = nn.Conv2d(3, self.conv1_filters, self.conv1_kernel_size)\n",
    "\n",
    "        self.conv1_updated_dim_h = inp_dim[1] - self.conv1_kernel_size[0] + 1\n",
    "        self.conv1_updated_dim_w = inp_dim[2] - self.conv1_kernel_size[1] + 1\n",
    "\n",
    "        self.conv2_filters = 16\n",
    "        self.conv2_kernel_size = (3,3)\n",
    "        self.conv2 = nn.Conv2d(self.conv1_filters, self.conv2_filters, self.conv2_kernel_size)\n",
    "\n",
    "        self.conv2_updated_dim_h = self.conv1_updated_dim_h - self.conv2_kernel_size[0] + 1\n",
    "        self.conv2_updated_dim_w = self.conv1_updated_dim_w - self.conv2_kernel_size[1] + 1\n",
    "\n",
    "        self.linear1 = nn.Linear(int(self.conv2_filters * self.conv2_updated_dim_h * self.conv2_updated_dim_w), num_hid)\n",
    "        self.linear2 = nn.Linear(num_hid, num_out)\n",
    "\n",
    "    def initialize(self):\n",
    "        nn.init.kaiming_uniform_(self.conv1.weight, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.conv2.weight, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.linear1.weight, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.linear2.weight, a=math.sqrt(5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear1(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.linear2(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "def get_means_stds(dataset, h, w):\n",
    "    means = []\n",
    "    stds = []\n",
    "\n",
    "    num_channels = None\n",
    "    X = []\n",
    "\n",
    "    num_points = 0\n",
    "    for data in dataset:\n",
    "        num_points += 1\n",
    "\n",
    "        image, label = data\n",
    "\n",
    "        if num_channels == None:\n",
    "            num_channels = image.shape[0]\n",
    "\n",
    "        X.append(image)\n",
    "\n",
    "    X = torch.cat([t.unsqueeze(0) for t in X])\n",
    "    X = X.reshape((num_channels, num_points, h, w))\n",
    "\n",
    "    for channel in range(num_channels):\n",
    "        means.append(X[channel, :].mean().item())\n",
    "        stds.append(X[channel, :].std().item())\n",
    "\n",
    "    return means, stds\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean=[0.474, 0.473, 0.473], std=[0.252, 0.252, 0.251])\n",
    "transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), normalize])\n",
    "\n",
    "cifar10_train = torchvision.datasets.CIFAR10('./data', train=True, download=True, transform=transforms)\n",
    "cifar10_test = torchvision.datasets.CIFAR10('./data', train=False, download=True, transform=transforms)\n",
    "\n",
    "# means, std = get_means_stds(cifar10_train, 32, 32)\n",
    "# print(\"means: {}\".format(means))\n",
    "# print(\"std: {}\".format(std))\n",
    "\n",
    "dl_train = torch.utils.data.DataLoader(cifar10_train, batch_size=batch_size, shuffle=True)\n",
    "dl_test = torch.utils.data.DataLoader(cifar10_test, batch_size=10000, shuffle=False)\n",
    "\n",
    "model = CIFAR10_CNN((3, 32, 32), 128, 10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebe4e51-311d-4ae5-8e56-f30978b0cdfa",
   "metadata": {
    "id": "6ebe4e51-311d-4ae5-8e56-f30978b0cdfa"
   },
   "outputs": [],
   "source": [
    "# module wrapper with respective optimizer stack\n",
    "\n",
    "# Optimizers used to obtain the results\n",
    "# Optimizers in which clip is set to True have gradient clipping enabled.\n",
    "# Gradient clipping is disabled by default.\n",
    "\n",
    "import gdtuo_gradient_clipping as gdtuo\n",
    "\n",
    "# Adam as primary optimizer, no secondary optimizer\n",
    "# gdtuo_optimizer = gdtuo.Adam()\n",
    "\n",
    "# Adam / SGD(alpha = 10^-9) with no gradient clipping for SGD as secondary optimizer\n",
    "gdtuo_optimizer = gdtuo.Adam(optimizer=gdtuo.SGD(alpha=1e-9))\n",
    "\n",
    "# Adam / SGD(alpha = 10^-9) with gradient clipping for SGD as secondary optimizer\n",
    "# gdtuo_optimizer = gdtuo.Adam(optimizer=gdtuo.SGD(alpha=1e-9, clip=True))\n",
    "\n",
    "# gdtuo_optimizer = gdtuo.Adam(optimizer=gdtuo.SGD(alpha=1e-8))\n",
    "# gdtuo_optimizer = gdtuo.Adam(optimizer=gdtuo.SGD(alpha=1e-8, clip=True))\n",
    "# gdtuo_optimizer = gdtuo.Adam(optimizer=gdtuo.SGD(alpha=1e-7))\n",
    "# gdtuo_optimizer = gdtuo.Adam(optimizer=gdtuo.SGD(alpha=1e-7, clip=True))\n",
    "# gdtuo_optimizer = gdtuo.Adam(optimizer=gdtuo.SGD(alpha=1e-6))\n",
    "# gdtuo_optimizer = gdtuo.Adam(optimizer=gdtuo.SGD(alpha=1e-6, clip=True))\n",
    "# gdtuo_optimizer = gdtuo.Adam(optimizer=gdtuo.SGD(alpha=1e-5))\n",
    "# gdtuo_optimizer = gdtuo.Adam(optimizer=gdtuo.SGD(alpha=1e-5, clip=True))\n",
    "# gdtuo_optimizer = gdtuo.Adam(optimizer=gdtuo.SGD(alpha=1e-4))\n",
    "# gdtuo_optimizer = gdtuo.Adam(optimizer=gdtuo.SGD(alpha=1e-4, clip=True))\n",
    "# gdtuo_optimizer = gdtuo.Adam(optimizer=gdtuo.SGD(alpha=2.5e-3))\n",
    "# gdtuo_optimizer = gdtuo.Adam(optimizer=gdtuo.SGD(alpha=2.5e-3, clip=True))\n",
    "# gdtuo_optimizer = gdtuo.Adam(optimizer=gdtuo.SGD(alpha=5e-3))\n",
    "# gdtuo_optimizer = gdtuo.Adam(optimizer=gdtuo.SGD(alpha=5e-3, clip=True))\n",
    "# gdtuo_optimizer = gdtuo.Adam(optimizer=gdtuo.SGD(alpha=1e-3))\n",
    "# gdtuo_optimizer = gdtuo.Adam(optimizer=gdtuo.SGD(alpha=1e-3, clip=True))\n",
    "# gdtuo_optimizer = gdtuo.Adam(optimizer=gdtuo.SGD(alpha=1e-2))\n",
    "# gdtuo_optimizer = gdtuo.Adam(optimizer=gdtuo.SGD(alpha=1e-2, clip=True))\n",
    "\n",
    "# Creates module wrapper with optimizer stack functionality\n",
    "mw = gdtuo.ModuleWrapper(model, optimizer=gdtuo_optimizer)\n",
    "mw.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0b968a-32d1-408f-8af9-6e6fcbf93830",
   "metadata": {
    "id": "9c0b968a-32d1-408f-8af9-6e6fcbf93830"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dl_train, num_epochs):\n",
    "    print()\n",
    "    print_model_optimizer_parameters(model)\n",
    "    for i in range(1, num_epochs + 1):\n",
    "        total_loss = 0.0\n",
    "        for j, (features_, labels_) in enumerate(dl_train):\n",
    "            model.begin() # before each step, enables gradient tracking on desired parameters\n",
    "            features, labels = features_.to(device), labels_.to(device)\n",
    "            prediction = model.forward(features)\n",
    "            loss = F.nll_loss(prediction, labels)\n",
    "            model.zero_grad()\n",
    "            loss.backward(create_graph=True)\n",
    "            model.step()\n",
    "            total_loss += loss.item() * features_.size(0)\n",
    "\n",
    "        train_loss = total_loss / len(dl_train.dataset)\n",
    "        print(\"\\nepoch: {}, train loss: {}\".format(i, train_loss))\n",
    "        print_model_optimizer_parameters(model)\n",
    "\n",
    "# Function to output the model's primary optimizer's hyperparameter values\n",
    "# For example, if the stack was Adam / SGD, it would output the hyperparameter values of Adam\n",
    "def print_model_optimizer_parameters(model):\n",
    "    optimizer = model.optimizer\n",
    "    if isinstance(optimizer, gdtuo.NoOpOptimizer):\n",
    "        print(\"No optimizer passed into gdtuo model.\")\n",
    "        return\n",
    "\n",
    "    optimizer_type = \"unknown\"\n",
    "    if isinstance(optimizer, gdtuo.SGD):\n",
    "        optimizer_type = \"SGD\"\n",
    "    elif isinstance(optimizer, gdtuo.SGDPerParam):\n",
    "        optimizer_type = \"SGDPerParam\"\n",
    "    elif isinstance(optimizer, gdtuo.AdaGrad):\n",
    "        optimizer_type = \"AdaGrad\"\n",
    "    elif isinstance(optimizer, gdtuo.RMSProp):\n",
    "        optimizer_type = \"RMSProp\"\n",
    "    elif isinstance(optimizer, gdtuo.RMSPropAlpha):\n",
    "        optimizer_type = \"RMSPropAlpha\"\n",
    "    elif isinstance(optimizer, gdtuo.Adam):\n",
    "        optimizer_type = \"Adam\"\n",
    "    elif isinstance(optimizer, gdtuo.AdamBaydin):\n",
    "        optimizer_type = \"AdamBaydin\"\n",
    "\n",
    "    print(\"{} optimizer parameters:\".format(optimizer_type))\n",
    "\n",
    "    optimizer_parameters = optimizer.parameters\n",
    "\n",
    "    for parameter in optimizer_parameters:\n",
    "        value = optimizer_parameters[parameter]\n",
    "        if parameter == \"alpha\" and \\\n",
    "        (isinstance(optimizer, gdtuo.RMSProp) or isinstance(optimizer, gdtuo.RMSPropAlpha)):\n",
    "            value = torch.square(value)\n",
    "        if parameter == \"beta1\" or parameter == \"beta2\":\n",
    "            value = gdtuo.Adam.clamp(value)\n",
    "        if parameter == \"gamma\":\n",
    "            value = gdtuo.RMSProp.clamp(value)\n",
    "        print(\"{}: {}\\t\".format(parameter, value), end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07db35e9-5878-487f-aa70-b7b2dab37245",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07db35e9-5878-487f-aa70-b7b2dab37245",
    "outputId": "35da9a84-72c9-42d4-fcdd-a74163e17b25"
   },
   "outputs": [],
   "source": [
    "train_model(mw, dl_train, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e3a6fe-63ee-4dd7-9882-3f0e1cbe9ca0",
   "metadata": {
    "id": "f2e3a6fe-63ee-4dd7-9882-3f0e1cbe9ca0"
   },
   "outputs": [],
   "source": [
    "def get_accuracy_error(model, dl_data):\n",
    "    num_correct_classifications = 0\n",
    "    num_datapoints = len(dl_data.dataset)\n",
    "    for j, (features_, labels_) in enumerate(dl_data):\n",
    "        features, labels = features_.to(device), labels_.to(device)\n",
    "        prediction = model.forward(features)\n",
    "        for i, row_in_prediction in enumerate(prediction):\n",
    "            predicted_label = torch.argmax(row_in_prediction)\n",
    "            if predicted_label == labels[i]:\n",
    "                num_correct_classifications += 1\n",
    "\n",
    "    accuracy = num_correct_classifications / num_datapoints\n",
    "    error = 1 - accuracy\n",
    "\n",
    "    return accuracy, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1459e200-486e-45ef-b77b-e8267bf858f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1459e200-486e-45ef-b77b-e8267bf858f9",
    "outputId": "976dcf5f-47fd-424f-f1b5-c4becbed2d93"
   },
   "outputs": [],
   "source": [
    "print(\"results from model\")\n",
    "\n",
    "# outputs accuracy of the model with the corresponding optimizer stack\n",
    "\n",
    "train_accuracy, train_error = get_accuracy_error(mw, dl_train)\n",
    "print(\"train accuracy: {}%\".format(train_accuracy * 100))\n",
    "print(\"train error: {}%\".format(train_error * 100))\n",
    "\n",
    "test_accuracy, test_error = get_accuracy_error(mw, dl_test)\n",
    "print(\"test accuracy: {}%\".format(test_accuracy * 100))\n",
    "print(\"test error: {}%\".format(test_error * 100))\n",
    "\n",
    "print()\n",
    "\n",
    "# outputs gradient information of the primary optimizer's parameters\n",
    "mw.optimizer.print_parameter_gradient_info()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
